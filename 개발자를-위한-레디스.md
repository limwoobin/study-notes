# 개발자를 위한 레디스

레디스는 싱글스레드로 동작한다. 정확히는 메인 스레드1개와 별도의 스레드 3개, 총 4개의 스레드로 동작한다.

## Chapter 03 자료구조
- 키에 저장된 아이템이 많은 경우 삭제 시 DEL 이 아니라 UNLINK 를 사용하는것이 좋다.
DEL 은 동기로 삭제되기에 싱글스레드인 레디스에서 커맨드 시간이 오래걸릴 수 있지만 UNLINK 의 경우
비동기로 백그라운드에서 키를 삭제하기 때문이다.

## Chapter 04 자료구조 활용
- SortedSet 을 이용한 실시간 리더보드 및 집계 + 가중치
- SortedSet 을 이용한 최근 검색기록 구현
- SortedSet 을 이용한 태그 기능 (그냥 Set 으로도 가능할덧)
- 랜덤 데이터 추출

카운팅 기법
- Set 으로 좋아요 처리하기
- Hash 를 이용한 채팅 안읽은 메시지 수 구하기
- 비트맵을 이용한 DAU 구하기
- HyperLogLog 를 이용한 어플리케이션 미터링
- Geo 자료구조를 이용한 위치데이터

비트맵은 뭐지?



HyperLogLog 가 뭐지?
매우 적은 메모리로 집합의 원소 개수를 추정할 수 있는 방법입니다. 집합의 원소 개수를 정확하게 계산하기 위해 아주 많은 메모리가 필요할 때나 하나의 메모리에 모두 담을 수 없을 정도로 원소의 개수가 많을 때, 정확하지 않지만 최대한 정확한 값을 상대적으로 적은 메모리만 사용해 얻고 싶을 때 사용할 수 있는 방법입니다.

해시셋과 비교했을때 약간의 오차율은 있지만 훨씬 적은메모리로 추정치를 파악할 수 있다

어떻게 처리하길래 그런걸까??
>> HyperLogLog의 핵심 아이디어는 정수의 상위 비트에 대한 확률적인 접근에서부터 시작한다. 
어떤 정수가 있을 때 상위 첫 번째 비트가 0인 정수 또는 상위 첫 번째 비트가 1인 정수는 각각 전체 표현 가능한 정수 중 50%를 차지한다. 
마찬가지로 상위 비트가 00, 01, 10, 11로 시작하는 정수 각각에 대한 최대 cardinality는 
전체 표현 가능한 정수의 25%가 된다. 
HyperLogLog에서는 이렇게 상위 몇 비트(b)를 사용할 것인지에 따라 레지스터의 개수(m=2b)가 결정된다. 
그리고 레지스터별 최대 cardinality는 '전체 표현 가능 정수 개수' × hyperlog 5개이다. 
당연히 레지스터 개수를 늘이면 좀 더 정해에 가까운 추정 값을 계산할 수 있다.


## 레디스 캐시로 사용하기

### 캐싱 전략

읽기 전략 - Look Aside 
- 가장 일반적으로 사용하는 방식
	- 찾고자 하는 데이터가 먼저 캐시에 있는지를 확인한 뒤, 캐시에 데이터가 있으면 캐시에서 읽어온다.
	- 캐시에 데이터가 없을 경우에는 직접 데이터베이스에 접근해 데이터를 조회한다.
	- 그 뒤, 어플리케이션은 이를 다시 캐시에 저장한다.
	- 장점: 레디스에 문제가 생겨 접근할 수 없는 상황이 발생하더라도 서비스 장애로 이어지지 않고 DB 를 통해 데이터를 조회할 수 있다.
	- 단점: 기존에 레디스를 통한 연결이 매우 많았다면 모든 커넥션이 DB 로 몰리기에 이슈가 발생할 수 있다


캐시를 이용한 쓰기 전략

1. write through
- DB에 업데이트 할때마다 매번 캐시에도 데이터를 함께 업데이트 시키는 방법
- 장점: 캐시는 항상 회신 데이터를 가지고 있다.
- 단점: 매번 2개의 저장소에 저장돼야 하기에 데이터를 쓸때마다 시간이 많이 소요된다

2. cache invalidation
- DB 에 값을 업데이트할때마다 캐시에서는 데이터를 삭제하는 방법
- 저장소에서는 특정 데이터를 삭제하는것이 저장하는것 보다 리소스를 적게 사용하기에 write through 의 단점을 보완한 방법

3. write behind(write back)
- 쓰기가 빈번한 상황인 경우 유용한데, 대량의 쓰기작업이 발생하면 우선 캐시에 업데이트 한 뒤, 특정 건수나 시간 간격으로 비동기로 DB 에 업데이트하는 방식
- e.g) 좋아요 기능이나 스트리밍 집계같은 기능에 유용하다


> NOTE
레디스에서는 키가 만료되었다고 바로 삭제되는것이 아님. 키는 passive 방식과 active 방식 이 두가지로 삭제됨
- passive 방식: 클라이언트가 키에 접근하고자 할때 키가 만료되었다면 메모리에서 수동적으로 삭제.
사용자가 접근할때만 수동적으로 삭제되기에 이를 passive 방식의 만료라고 함. 
그러나 사용자가 다시 접근하지 않는 경우도 있어 이 방식만으로는 충분하지 않음

- active 방식: TTL 값이 있는 키 중 20개를 랜덤하게 뽑은 뒤, 만료된 키를 모두 메모리에서 삭제함
만약 25% 이상의 키가 삭제되었다면 다시 20개의 키를 랜덤하게 뽑은 뒤 확인하고, 
아니라면 뽑아놓은 20개의 키 집합에서 다시 확인함. 이를 1초에 10번씩 수행


### 메모리 관리

레디스에서는 데이터의 최대 용량을 설정하는 maxmemory 설정과 이 용량을 초과할때의 처리 방식을 결정하는 
maxmemory-policy 설정값을 사용해 메모리를 관리함.

#### Noeviction (default)
- 레디스에 데이터가 가득차더라도 데이터를 삭제하지 않고 더 이상 데이터를 저장할 수 없다는 에러를 반환

#### LRU eviction
- 레디스에 데이터가 가득 찼을 때 가장 최근에 이용되지 않은 데이터부터 삭제하는 정책, 
즉 가장 오랫동안 사용되지 않은 데이터
	- volatile-lru: 만료시간이 설정되있는 키에 한해 LRU 방식으로 키를 삭제, 
	다만 모든 키가 만료시간이 없다면 noeviction 상황과 동일할수도
	- allkeys-LRU: 모든 키에 대해 LRU 알고리즘을 이용해 데이터를 삭제함

#### LFU eviction
- 가장 자주 사용되지 않은 데이터부터 삭제하는 정책(가장 조금 사용된 데이터)
	- volatile-lfu
	- allkeys-lfu

#### RANDOM eviction
- 레디스에 저장된 키 중 하나를 임의로 골라내 삭제, 따로 삭제될 키값을 계산하지 않아도 되어 부하를 줄여줄 수 있음
- 다만, 랜덤으로 데이터를 삭제하기에 자주 사용되는 데이터가 삭제될수도 있어서 오히려 불필요함을 유발할 수 있음
	- volatile-random
	- allkeys-random

#### volatile-ttl
- 만료시간이 가장 작은 키를 삭제


### 캐시 스탬피드 현상
- 캐시가 만료되어 여러 어플리케이션에서 동시에 DB 를 조회하고 이후 동시에 Redis 에 데이터를 쓰는 현상
이때, 연산이 많거나 한다면 DB와 어플리케이션에 순간 부하르 줄 수 있어 위험하다

### 레디스에서의 캐시와 세션스토어의 차이
- 캐시는 DB 의 완벽한 서브셋으로 동작함 즉, 캐시가 갖고있는 데이터는 모두 DB에 저장되어있으며 
캐시가 유실되더라도 해당 데이터는 DB에서 찾을 수 있음
- 캐시에 저장된 데이터는 여러 어플리케이션에서 같이 사용할 수 있음
- 세션스토어의 정보는 DB가 아닌 세션스토어에 일단 저장됨(세션이 활성화되어있는 동안에는), 
이후 유저가 로그아웃하면 데이터의 종류에 따라 DB에 저장할지 삭제될지 결정됨
- 세션스토어에 저장된 데이터는 여러 사용자 간 공유되지 않으며 특정 사용자ID 에 한해 유용함


## 레디스를 메시지 브로커로 사용하기

메시지 브로커는 크게 메시징 큐와 이벤트 스트림이라는 두가지 형태로 나눌 수 있다

메시징 큐와 이벤트 스트림의 차이
- 메시징 큐는 생산자가 소비자의 큐로 데이터를 직접 푸시, 반면 이벤트스트림은 소비자가 메시지를 pull 한다
- 메시징 큐는 소비자가 데이터를 읽어갈때 큐에서 데이터를 삭제한다, 반면 이벤트 스트림은 데이터가 바로 삭제되지 않고 특정 기간동안 저장될 수 있다
- 메시징 큐는 일대일 상황에서 한 서비스가 다른 서비스에게 동작을 지시할때 유용하게 사용될 수 있다
- 스트림은 다대다 상황에서 유리함을 확인할 수 있다

레디스의 pub/sub 은 fire-and-forget 패턴이 필요한 간단한 알림같은 서비스에서는 유용하게 쓸 수 있다

> fire-and-forget
어떤 작업을 실행하고 그 결과에 대한 응답을 기다리지 않고 바로 다음 코드를 실행하는 것을 의미.
주로, 성능 향상이나 비동기 작업을 수행할때 사용됨


### 클러스터 구조에서의 pub/sub
- 클러스터에서 pub/sub 을 사용할때 메시지를 발행하면 해당 메시지는 클러스터에 속한 모든 노드에게 자동으로 전달된다. 따라서, 아무 노드에 연결해 SUBSCRIBE 커맨드를 사용하면 데이터를 수신할 수 있다.
(다만 클러스터 입장에서는 효율적인 방식은 아니다, 그래서 이를 해결하기 위해 shared pub/sub 이 나옴)

### shared pub/sub
- 각 채널은 슬롯에 매핑됨, 같은 슬롯을 가지고 있는 노드간에만 pub/sub 메시지를 전파함

### list 의 블로킹 기능
- BLPOP, BRPOP 은 각각 LPOP, RPOP 에 블로킹기능을 추가한 커맨드이다
- 이는 list 에 데이터를 요청하고 데이터가 있으면 바로 반환, 없다면 특정 시간만큼 기다렸다가 
있으면 값을 반환하고 없으면 nil 을 반환한다
- BLPOP 은 LPOP 과 다르게 두개의 데이터를 반환한다. (key, value) 왜냐하면 
여러개의 값을 기다리다가 그 중 어떤 값이 들어왔는지 알기 위해서이다


## Redis Stream

대용량, 대규모의 메시징 데이터를 빠르게 처리할 수 있는 자료구조, 데이터를 지우지 않고 계속해서 추가하는 방식으로 저장됨(append-only)
레디스 Stream은 카프카의 영향을 많이받은 시스템인 만큼 카프카와 유사한 기능을 가지고 있으며, 일부 기능은 카프카보다 뛰어난 처리를 할 수 있도록 설계됨

카프카는 토픽이라는 곳에 데이터를 저장하지만 레디스는 Stream 자료구조를 이용한다.
자료구조 자체가 스트림이 되는것이다

레디스 스트림의 메시지는 시간과 그리고 관련된 유니크ID 를 가진다, 이 값은 중복되지 않는다.

`<millisecondsTime>-<sequenceNumber>`

millisecondsTime: 실제 스트림에 아이템이 저장될 시점의 레디스 노드 로컬 시간
sequenceNumber: 동일한 밀리세컨드 시간에 저장된 데이터의 순서 (시퀀스 번호는 64bit)

+ ID 를 직접 지정할 수 있으며, 이후에 저장되는 ID 는 이전에 저장됐던 ID 보다 작을 수 없다

### 데이터의 조회

카프카에서는 토픽을 실시간으로 리스닝하면서 데이터를 조회한다.
레디스 Stream 에서는 데이터를 두 가지 방식으로 읽을 수 있다.
1) 카프카처럼 실시간으로 처리되는 데이터를 리스닝하는 방법 - XREAD
2) ID 를 이용해 필요한 데이터를 검색하는 방법 - XRANGE

XREAD 와 XRANGE 둘의 검색범위를 같이 조건하면 무슨차이가 있냐고 생각할 수 있지만 차이는 존재한다.
XREAD 는 조회가 완료된 이후 신규로 들어온 메시지를 계속해서 반환하지만, XRANGE 는 모든 데이터를 조회한 이후
종료된다는 차이가 있다.


### 레디스 스트림의 컨슈머 그룹

레디스 스트림은 카프카와 다르게 메시지가 전달되는 순서를 신경쓰지 않아도 된다
레디스 스트림에서 컨슈머 그룹내의 한 컨슈머는 다른 컨슈머가 아직 읽지 않은 데이터만을 읽어간다


### 보류리스트

레디스 스트림에서는 컨슈머 그룹에 속한 컨슈머가 메시지를 읽어가면 각 컨슈머별로 읽어간 메시지에 대해
리스트를 새로 생성하며(보류리스트), 마지막으로 읽어간 데이터의 ID 로 last_delivered_id 값을 업데이트한다. 
last_delivered_id 값은 해당 소비자 그룹에 마지막으로 전달한 ID 가 무엇인지를 파악해, 동일한 메시지를 중복으로 전달하지 않기 위해 사용된다

그리고 컨슈머에서 레디스 스트림에게 ACK 를 보내면 레디스 스트림은 해당 컨슈머의 보류리스트에서 ACK 받은 메시지를 삭제한다.
즉, 보류리스트를 통해 소비자가 처리한 데이터를 파악할 수 있다


## Chaptor07 - 레디스 데이터 백업방법

레디스를 복제구조(replication)로 사용할 경우 데이터가 실시간으로 복제본에 전달되고 있으니 
데이터를 백업할 필요를 못느낄 수 있다. 
하지만 복제와 백업은 목적이 다르다

- 복제: 고가용성을 위함
- 백업: 장애 상황으로부터의 데이터 복구

왜냐하면 복제의 경우 예를들어 의도치않게 데이터를 삭제하는 커맨드를 발생시킬 경우, 이는 바로 복제본으로 전달된다.
그렇기에, 복제만으로는 데이터를 안전하게 유지할 수 없다.

레디스는 RDB 와 AOF 두가지 백업 방식을 지원한다

- RDB: 일정 시점에 메모리에 저장된 데이터 전체를 저장(snapshot 방식)
- AOF: 레디스 인스턴스가 처리한 모든 쓰기 작업을 차례대로 기록, 복원시에는 파일을 다시 읽어가며 데이터 세트 재구성

저장방식
- AOF 는 레디스 프로토콜(RESP) 형태로 저장, RDB 파일은 바이너리 형태로 저장

장단점
- RDB: 시점 단위로 여러 백업본을 저장할 수 있고 AOF 보다 복원이 빠르다는 장점이 있음, 하지만 특정 시점으로의 복구는 불가능함
- AOF: RDB 파일보다 크기가 크고 주기적으로 압축해 재작성해야함, 하지만 원하는 시점으로 복구할 수 있다는 장점이 있음

+ 하나의 인스턴스에서 RDB 와 AOF 옵션을 동시에 사용하는 것도 가능하며, 일반적인 RDB 만큼의 안정성을 원하는 경우 
두가지 백업방식을 동시에 사용하는것을 권장함
+ 레디스에서 데이터를 복원할 수 있는 시점은 서버가 재시작될 때 뿐임, 인스턴스 실행 도중에는 데이터 파일을 읽어올 수 없음  
+ 레디스 서버는 재시작시 AOF 파일이나 RDB 파일이 존재하는지 확인한 뒤, 파일이 있는경우 파일을 로드함
이때 RDB 파일보다 AOF 파일이 더 내구성이 보장된다고 판단하기에 2개의 파일이 모두 존재하는 경우에는 AOF 파일을 로드함

RDB 의 백업방식
- 원하는 시점에 메모리 자체를 스냅샷 찍듯이 저장할 수 있음
- 원하는 주기에 한번씩 RDB 파일을 생성할 수 있음
- 저장될때마다 원격 저장소로 파일을 옮겨 2차 백업을 수행한다면 데이터 센터 장애 등 더 큰 장애에도 대처할 수 있음
- 하지만 장애 발생시 손실가능성을 최소화해야하는 경우 RDB 를 이용한 백업만으로는 적절치 않음, 지정한 시간 단위로 파일이 저장되기에 저장시점부터 장애발생직전까지는 데이터가 손실될 수 있음

AOF 의 백업방식
- 모든 쓰기 작업의 로그를 차례로 기록함, 실수로 FLUSHALL 커맨드로 데이터를 날렸다 해도 AOF 파일을 직접 열어
FLUSHALL 커맨드만 삭제한 뒤 레디스를 재시작하면 커맨드를 실행하기 직전까지로 데이터를 복구할 수 있음
- 다만 블로킹작업이 있는 커맨드는 AOF 파일에서 자동으로 변환되어 저장됨 (e.g BRPOP -> RPOP)
왜냐면, AOF 파일에서 블로킹 기능을 굳이 명시할 필요가 없기때문
- AOF 는 쓰기 커맨드가 그대로 저장되기에 크기가 계속 증가하게됨, 그래서 백업기능을 안정적으로 사용하기 위해 
주기적으로 파일을 압축시키는 재구성 작업이 필요함
	- 재구성은 기존 디스크의 AOF 를 사용하는것이 아니라 레디스 메모리의 데이터를 읽어와서 새로운 파일로 저장하는 형태로 동작함
	- RDB 파일을 저장할때와 마찬가지로 AOF 파일도 재구성할때 fork 를 이용해 자식 프로세스를 생성하며, 이 자식 프로세스가 AOF 파일을 재구성함
	- 버전 7 이전까지는 재구성을 하면 AOF 파일의 앞부분은 메모리를 읽어와 바이너리형태로 저장한 RDB 파일이 위치하고, 이후 메모리를 변경한 커맨드들은 RESP 형태로 RDB 파일의 뒤에 append 하게 쌓이는 형태로 증가함
	- 버전 7 이후부터는 바이너리 형태의 RDB 파일, 증가하는 RESP 형태의 AOF 파일을 나눠서 데이터를 관리함
	또한, 현재 레디스가 바라보고있는 파일이 어떤것인지 나타내는 매니페스트 파일을 도입하여 매니패스트 파일은 RDB 와 AOF 파일이 어떤것인지 알려주는 역할을 함
	- AOF 가 재구성될때마다 AOF 를 구성하는 각 RDB 와 AOF 파일명의 번호, 매니패스트 파일 내부의 seq 값도 1씩 증가한다

AOF 자동 재구성
- `auto-aof-rewrite-percentage`: AOF 파일을 다시 쓰기 위한 시점을 정하기 위한 옵션, 
마지막으로 재구성됐던 AOF 파일의 크기와 비교해 현재의 AOF 파일이 지정된 퍼센트만큼 커졌을때 재구성을 시도
마지막으로 재구성됀 파일의 크기는 `aof_base_size` 로 알수있음.
e.g) 마지막 재구성된 파일이 100이고 auto-aof-rewrite-percentage 가 100% 라면 크기가 200이 되었을때 재구성함
- `auto-aof-rewrite-min-size`: 재구성된 이후 AOF 파일의 최소 크기를 지정할 수 있음
e.g) 재구성을 시도해 생성된 RDB 파일의 크기가 너무 작다면 이는 재구성하는것이 비효율적일 수 있음, 그렇기에 특정 크기 이상인 경우에만 재구성함

AOF 수동 재구성
- 7 버전 이후부터는 AOF 저장시 타임스탬프를 같이 남길 수 있음, 이는 특정 시점으로 복원하는데에 유용함

AOF 파일의 안정성
- AOF 파일은 쓰기 커맨드를 AOF 파일에 기록한다고 했다. 
이때 WRITE 시 시스템콜을 호출하여 어플리케이션에서 파일에 저장하겠다고 하면 데이터는 커널영역의 OS 버퍼에
임시로 저장된다. 이후 운영체제가 판단하기에 커널에 여유가 있거나 최대 지연시간(30초)에 도달하면 커널 버퍼의 데이터를 디스크에 내려쓴다.

FSYNC - 커널의 OS 버퍼에 저장된 내용을 디스크에 내리도록 강제하는 시스템 콜

레디스에서는 쓰기 커맨드를 AOF 에 기록할때 `APPENDFSYNC` 옵션을 이용해 FSYNC 를 제어한다.
이는 파일 저장의 내구성을 제어하는것이다.
(사견 - APPENDFSYNC 옵션은 약간 카프카의 ack 와 비슷한 듯?)

- APPENDFSYNC no: AOF 데이터를 저장할때 WRITE 시스템콜을 호출, 데이터가 커널 영역에만 잘 저장되는지 확인하기에 쓰기성능이 가장 빠름
- APPENDFSYNC always: AOF 를 저장할때마다 WRITE 와 FSYNC 시스템콜을 함께 호출
즉, 매번 쓰고자 할때마다 데이터가 디스크에 저장되는것을 기다리기에 쓰기성능이 가장 느림
- APPENDFSYNC everysec: 데이터를 저장할때 WRITE 시스템콜을 호출하며, 1초에 한번씩 FSYNC 를 호출함
성능은 no 옵션 사용때와 거의 비슷

+ 기본옵션은 APPENDFSYNC everysec 이다, no 옵션 사용때와 거의 비슷하면서도 
서버 장애시 유실될수 있는 데이터는 최대1초이기에 속도와 안정성의 균형을 맞출 수 있는 값이다.
always 는 굉장히 느려질수있으며 no 의 경우 최대 30초 동안 입력했던 레디스의 데이터를 잃을 수 있음
그렇기에 everysec 옵션을 제일 권장함(속도와 안정성 모두 잡았다)

백업 주의사항
- RDB, AOF 파일을 사용하는 경우 레디스 인스턴스의 maxmemory 값은 실제 서버 메모리보다 여유를 갖고 사용하는것이 좋음

+ 왜냐면 백업할때 fork 로 자식프로세스가 백업하는데 이때 레디스 메모리를 그대로 파일에 저장한다 
이때 Copy-on-Write 방식을 이용하기에 실제 메모리페이지가 그대로 복제되어 메모리가 가득찰수 있기에 
결론은 여유를 가지고 사용해야한다 (백업을 염두하자)

## Chaptor08 - 복제

레디스의 복제본 노드가 필요한 이유
1. 서비스를 안정적으로 운영하기 위해 마스터가 다운되었을때 대신 사용할 여분의 복제본이 필요
2. 복제본은 트래픽을 감소시키는 역할을 수행할 수 있음, 일부 트래픽을 복제본을 바라보게 하여 부하분산 가능
3. 마스터 노드에서 매번 데이터의 백업을 받는것은 부담스러움. 이때 백업을 복제본에서 받으면 
백업작업이 서비스에 미치는 영향을 최소화 할 수 있음

복제 ID
- 모든 레디스 인스턴스는 복제ID(replicaiton Id) 를 가지고 있음
복제 기능을 사용하지 않는 인스턴스여도 모두 랜덤스트링 값의 복제ID 를 가지며, 복제ID 는 오프셋과 쌍으로 존재함
이는 레디스 내부의 데이터가 수정되는 모든 커맨드를 수행할때마다 오프셋이 증가함

부분 재동기화
- 네트워크 이슈로 복제연결이 끊길때마다 마스터의 RDB 파일을 새로 내려 복제본에 전달하면 레디스의 성능은 급격하게 나빠질것임
이를 방지하기 위해 레디스는 부분 재동기화 기능을 사용해 안정적인 복제 연결을 유지함
- 마스터는 커넥션 유실을 대비해 백로그 버퍼라는 메모리 공간에 복제본에 전달한 커맨드 데이터들을 저장해놓음
- 하나의 복제그룹에서 replication id 와 offset 을 이용하면 복제본이 어느 시점까지 데이터를 가지고 있는지 파악할 수 있음
- 복제연결이 만약 끊긴 뒤 재연결되면 복제본은 PSYNC 커맨드를 통해 자신의 replication id 와 오프셋을 마스터에게 전달
- 마스터의 현재 replicaion id, offset 과 전달받은 복제본의 replication id, offset 을 비교해 백로그 버퍼에 있는 내용을 복제본에게 전달함으로서 부분 재동기화를 진행함
- 하지만 백로그버퍼에 데이터가 없거나 replication id 가 마스터와 일치하지 않다면 전체 재동기화를 시도함

## Chaptor09 - 센티널

레디스 인스턴스와는 다른 역할을 하는 별도의 프로그램이며, 센티널의 자동 페일오버 기능을 사용하면 
마스터 인스턴스에 장애가 발생하더라도 레디스를 계속 사용할 수 있도록 동작해 다운타임을 최소화 할 수 있음(고가용성)

센티널 기능
- 모니터링
마스터, 복제본(레플리카)의 인스턴스 상태를 실시간으로 확인

- 자동 페일오버
마스터의 비정상 상태를 감지해 정상 상태인 복제본 중 하나를 마스터로 승격시킴, 
기존 마스터에 연결된 복제본은 새로 승격된 마스터에 연결됨

- 인스턴스 구성 정보 안내
센티널은 클라이언트에게 현재 구성에서의 마스터 정보를 알려줌
페일오버가 발생하면 변경된 마스터 정보를 재전달하기에 페일오버가 발생하더라도 레디스 엔드포인트를 변경할 필요는 없음

동작방식
1. 레디스가 센티널에 먼저 연결해 마스터의 정보를 가져옴
2. 가져온 마스터 정보로 연결

### 분산시스템으로 동작하는 센티널
- 레디스에서는 센티널이 SPOF 가 되는것을 방지하기 위해 센티널이 최소 3대 이상인 경우에만 정상적으로 동작할 수 있도록 
설계되었음, 하나의 센티널에 이상이 생기더라도 다른 센티널에서 계속해서 역할을 수행할 수 있음
- 센티널은 쿼럼이라는 개념이 있는데, 이는 마스터가 비정상 동작을 한다는것에 동의해야 한다는 개념임
센티널은 쿼럼을 이용한 과반수 선출개념을 사용하기에 일반적으로 3대, 좀더 견고하게 한다면 5대로 구성함
	- 센티널 인스턴스가 3대인 경우는 쿼럼은 2로 설정

- 센티널은 일반적으로 서로 다른 가용영역에 배치한다 (서로 영향받지 않기 위해)
- 보통 하나의 서버에 레디스 프로세스와 센티널 프로세스를 같이 배치함(동시에 실행)
- 기존 마스터 서버인 A가 죽어서 복제본 B가 마스터가 되었다고 하자, 이때 기존 마스터 A 가 다시 복구된다면
기존 마스터 A 서버는 복제본이 되어 마스터 B 를 바라본다

레디스 복제본들 중 마스터로 승격될때 필요한 자격
1. redis.conf 파일에 명시된 replica-priority 가 낮은 복제본
2. 마스터로부터 더 많은 데이터를 수신한 복제본
3. 2번 조건까지 동일하다면, runID 가 사전 순으로 작은 복제본
(작은 runID 를 선택하는건 특별한 의미는 없고, 임의로 하나의 노드를 선택하는 방식임)