# **Kafka**

## **Topic**

- 파티션은 늘릴 수는 있지만 다시 줄일 수는 없음
- 파티션 내의 데이터는 컨슈머가 컨슘한다해도 즉시 삭제되지 않음
- 동일 데이터에 대해선 아래의 경우 다른 컨슈머에 의해 두번 처리될 수 있음
  - 컨슈머 그룹이 다른 경우
  - auto.offset.reset = earliest 의 경우
- 삭제는 옵션에 따라 결정됨  
  log.retentions.ms: 최대 record 보존 시간  
  log.retention.byte: 최대 record 보존 크기 (byte)

<br>

## **Replication / broker**

- **파티션의 복제본을 저장하는곳**
  - replication 이 2라면 leader partion 1개 , follow partion 1개
  - replication 이 3이라면 leader partion - 1개 , follow partion - 2개

![kafka-image-1](https://user-images.githubusercontent.com/28802545/158009223-9c4b3c30-cbd7-4b0e-9928-1a837c91b473.PNG)

- **ack option**
  - **ack 0**
    - producer 는 leader partion 에 data 를 전송하고 응답값을 받지 않음
    - 그렇기 때문에 leader partion에 데이터가 정상적으로 전송되었는지 나머지 partion에 정상적으로 복제되었는지 보장할 수 없음
    - 속도는 빠르지만 데이터 유실 가능성이 있음
  - **ack 1**
    - producer 는 leader partion 에 data 를 전송하고 응답값을 받음
    - 다만 나머지 partion에 복제되었는지는 알 수 없음
    - 데이터 유실 가능성 존재
  - **ack all**
    - producer 는 leader partion 에 data 를 전송하고 응답값을 받음
    - 나머지 partion에도 data가 저장되는 것까지 확인함
    - 데이터 유실은 없는대신 0,1 에 비해 확인과정이 많기때문에 속도가 느림

<br>

- **파티셔너(Partitioner): 프로듀서가 data를 보내면 파티셔너를 통해 브로커로 데이터가 전달됨**

  - **메시지 키가 있는경우**

    - 메시지키를 가진 레코드는 파티셔너에 의해 특정한 hash 값이 생성됨, 이 hash값을 기준으로 어느 파티션에 들어갈지 결정됨
    - 동일한 키를 가진 레코드는 동일한 파티션으로 순차적으로 들어가게됨 (queue 처럼 동작)

  - **메시지 키가 없는경우**
    - `round-robin` 방식으로 파티션에 들어가게됨
    - 그런데 일반적인 `round-robin` 과는 약간 다르게 `UniformStickyPartitioner` 이라는 파티셔너가 프로듀서에서 배치로 모을수 있는 최대한의 레코드를 모아 파티션으로 데이터를 전송 (파티셔너를 따로 설정하지 않은 경우 default 가 `UniformStickyPartitioner`)
    - custom 파티셔너를 사용할 수 있게 파티셔너 interface 제공

- **lag**

  - producer 가 data 를 넣는 속도가 consumer 가 data 를 가져가는 속도보다 빨라 둘의 offset 차이가 발생하는것, 둘의 offset 차이를 lag 이라 한다. (producer offset: 토픽의 가장 최근 offset)

    ![kafka-image-2](https://user-images.githubusercontent.com/28802545/158011764-7bab74ee-7553-4641-b071-bc592f643bb8.PNG)

  - partion이 여러개인 경우 lag 도 여러개가 존재할 수 있음
  - lag 중 가장 높은 숫자의 lag 을 `redords-lag-max` 라고 함
  - lag 모니터링 도구로는 LinkedIn 에서 만든 [Burrow](https://github.com/linkedin/Burrow) 가 있음

- **메시지브로커와 이벤트브로커**

  - 메시지브로커는 메시지브로커 역할만 가능  
    이벤트 브로커는 이벤트,메시지 브로커 둘의 역할 모두 수행 가능
  - 메시지브로커 특징
    - 메시지를 받아 적절히 처리하고 나면 즉시 or 짧은 시간 내에 데이터가 삭제되는 구조
    - ex) redis queue, rabbitmq
  - 이벤트브로커 특징
    - 이벤트 or 메시지라고 불리는 레코드를 인덱스를 통해 개별 엑세스를 관리
    - 필요한 시간동안 이벤트를 보존 가능
    - 이벤트를 저장함으로서 얻는 이점은 장애 발생시 장애가 일어난 지점부터 재처리 가능 / 많은 양의 stream data를 효과적으로 처리 가능
    - ex) kafaka, aws kinesis, aws sqs

- **컨슈머(Consumer)**

  - 파티션과 컨슈머는 N:1 의 관계를 가질 수 있다.

    - 파티션2개 컨슈머1개이면 1개의 컨슈머가 2개의 파티션을 모두 컨슘한다.
    - 파티션2개 컨슈머2개이면 각각의 파티션을 각각의 컨슈머가 컨슘한다.
    - 파티션2개 컨슈머3개이면 컨슈머 하나는 아무일도 하지않고 놀게된다.
    - 즉, 컨슈머의 개수는 파티션의 개수보다 같거나 작아야 한다.

<br>

- 하나의 토픽은 여러개의 컨슈머 그룹으로부터 컨슘될 수 있다.
  - 각각의 컨슈머 그룹은 독립적이어서 서로에게 영향을 주지 않는다.
- 아래와 같이 컨슈머된 데이터를 하나의 컨슈머그룹에선 elastic search 에 적재하고 다른 컨슈머 그룹에선 hadoop 에 적재하는식의 활용이 가능하다.

![kafka-image-3](https://user-images.githubusercontent.com/28802545/158048767-e36120cf-3996-4243-b79c-20800712a2fd.PNG)

- **Kafka Streams**

  - Kafka 와 완벽 호환
  - 데이터 유실혹은 중복처리가 되지않고 한번만 처리되는것을 보장한다
  - 스케줄링 도구가 필요 없음
    이벤트 처리 기능(Streams DSL , Processor API) 제공
  - 자체 로컬 상태 저장소를 사용
    - 상태 기반 처리를 돕기 위해 rocksDB 를 로컬에서 사용하여 상태를 저장

- **Streams vs Consumer**  
  `Consumer`와의 어떤 차이가 있을까

  - `Consumer`는 메시지를 받아 단순히 처리하고 끝낸다
  - `Kafka Streams`는 메시지를 받아 연속된 처리를 하는 pipeline 구성 가능  
    ex) 메시지의 민감 데이터 마스킹,  
    1분 간격으로 메시지 특정 이벤트 감지

### Kafka Zero-Copy

- kafka는 메시지 전송시 `zero-copy` 방식을 사용  
  (기존에는 read하고 send하기 떄문에 메모리 복사, 컨텍스트 스위칭이 있어 비용이 비쌌음)

기존 방식

```
1. 클라이언트가 서버에게 정적 파일을 요청
2. 서버의 웹 어플리케이션이 요청을 받음
3. 웹 어플리케이션(유저 영역)이 디스크에서 파일 데이터를 읽기 위해서 커널(커널 영역)이 파일 데이터를 읽도록 요청
4. 파일을 다 읽은 후 커널(커널 영역)이 다시 웹 어플리케이션(유저 영역)으로 데이터를 반환
5. 하지만 웹 어플리케이션(유저 영역)은 클라이언트에 반환하기 위해서 소켓에 파일 데이터를 넣어야 하므로 다시 커널(커널 영역)에 요청
6. 커널(커널 영역)은 소켓을 처리
```

위 4,5번 항목의 작업에서 불필요한 `Context Switching`이 많이 발생  
이에 반해 `zero-copy`는 커널영역에서 데이터를 읽은 후 웹 어플리케이션 영역으로 돌아가지 않고 바로 소켓에 데이터를 담아 전달(말 그대로 무복사)

### Kafka 핵심 개념

- 분산 처리
  - 간편하게 브로커의 수를 확장할 수 있음
- 페이지 캐시
  - OS의 성능을 높이기 위해 캐시를 사용함, 디스크I/O에 대한 접근이 줄어 성능을 높일 수 있음
- 배치 전송 처리
  - 로그성 시스템은 실시간으로 전송할 필요가 없으니 배치로 전송할때 효율적임
- 압축 전송
  - 압축은 네트워크 대역폭이나 회선 비용을 줄이는데 효과적
  - 앞선 배치전송과 결합해 사용하면 더 높은 효율이 있음
- 토픽, 파티션, 오프셋
- 고가용성 (High Availability)
  - 무조건 팔로워수가 많다고 좋은것이 아니다  
    팔로워 수 많큼 브로커의 디스크 공간도 소비되므로 이상적인 리플리케이션 팩터 수를 유지해야 한다.  
    일반적으로 3으로 구성하도록 권장
